\documentclass[psamsfonts]{amsart}
%
%-------Packages---------
%
\usepackage[h margin=1 in, v margin=1 in]{geometry}
\usepackage{amssymb,amsfonts}
\usepackage[all,arc]{xy}
\usepackage{enumerate}
\usepackage{mathrsfs}
\usepackage{amsthm}
\usepackage{mathpazo}
\usepackage{yfonts}
\usepackage{enumitem}
\usepackage{mathrsfs}
\usepackage{fourier-orns}
\usepackage[all]{xy}
\usepackage{hyperref}
\usepackage{cite}
\usepackage{url}
\usepackage{mathtools}
\usepackage{graphicx}
\usepackage{pdfsync}
\usepackage{mathdots}
%
\usepackage{tgpagella}
\usepackage[T1]{fontenc}
%
\usepackage{listings}
\usepackage{color}

\definecolor{dkgreen}{rgb}{0,0.6,0}
\definecolor{gray}{rgb}{0.5,0.5,0.5}
\definecolor{mauve}{rgb}{0.58,0,0.82}

\lstset{frame=tb,
  language=Matlab,
  aboveskip=3mm,
  belowskip=3mm,
  showstringspaces=false,
  columns=flexible,
  basicstyle={\small\ttfamily},
  numbers=none,
  numberstyle=\tiny\color{gray},
  keywordstyle=\color{blue},
  commentstyle=\color{dkgreen},
  stringstyle=\color{mauve},
  breaklines=true,
  breakatwhitespace=true,
  tabsize=3
  }
%
%--------Theorem Environments--------
%
\newtheorem{thm}{Theorem}[section]
\newtheorem*{thm*}{Theorem}
\newtheorem{cor}[thm]{Corollary}
\newtheorem{prop}[thm]{Proposition}
\newtheorem{lem}[thm]{Lemma}
\newtheorem*{lem*}{Lemma}
\newtheorem{conj}[thm]{Conjecture}
\newtheorem{quest}[thm]{Question}
%
\theoremstyle{definition}
\newtheorem{defn}[thm]{Definition}
\newtheorem*{defn*}{Definition}
\newtheorem{defns}[thm]{Definitions}
\newtheorem{con}[thm]{Construction}
\newtheorem{exmp}[thm]{Example}
\newtheorem{exmps}[thm]{Examples}
\newtheorem{notn}[thm]{Notation}
\newtheorem{notns}[thm]{Notations}
\newtheorem{addm}[thm]{Addendum}
\newtheorem{exer}[thm]{Exercise}
%
\theoremstyle{remark}
\newtheorem{rem}[thm]{Remark}
\newtheorem*{claim}{Claim}
\newtheorem*{aside*}{Aside}
\newtheorem*{rem*}{Remark}
\newtheorem*{hint*}{Hint}
\newtheorem*{note}{Note}
\newtheorem{rems}[thm]{Remarks}
\newtheorem{warn}[thm]{Warning}
\newtheorem{sch}[thm]{Scholium}
%
%--------Macros--------
\renewcommand{\qedsymbol}{$\blacksquare$}
\renewcommand{\hom}{\mathsf{Hom}}
\renewcommand{\emptyset}{\varnothing}
\newcommand{\R}{\mathbb{R}}
\newcommand{\ib}[1]{\textbf{\textit{#1}}}
\newcommand{\Q}{\mathbb{Q}}
\newcommand{\Z}{\mathbb{Z}}
\newcommand{\N}{\mathbb{N}}
\newcommand{\C}{\mathbb{C}}
\newcommand{\A}{\mathbb{A}}
\newcommand{\F}{\mathbb{F}}
\newcommand{\M}{\mathcal{M}}
\renewcommand{\S}{\mathbb{S}}
\newcommand{\V}{\vec{v}}
\newcommand{\RP}{\mathbb{RP}}
\newcommand{\CP}{\mathbb{CP}}
\newcommand{\B}{\mathcal{B}}
\newcommand{\GL}{\mathsf{GL}}
\newcommand{\SL}{\mathsf{SL}}
\newcommand{\SP}{\mathsf{SP}}
\newcommand{\SO}{\mathsf{SO}}
\newcommand{\SU}{\mathsf{SU}}
\newcommand{\gl}{\mathfrak{gl}}
\newcommand{\g}{\mathfrak{g}}
\newcommand{\inv}{^{-1}}
\newcommand{\bra}[2]{ \left[ #1, #2 \right] }
\newcommand{\ind}{\lambda \in \Lambda}
\newcommand{\set}[1]{\left\lbrace #1 \right\rbrace}
\newcommand{\abs}[1]{\left\lvert#1\right\rvert}
\newcommand{\norm}[1]{\left\lVert#1\right\rVert}
\newcommand{\transv}{\mathrel{\text{\tpitchfork}}}
\newcommand{\enumbreak}{\ \\ \vspace{-\baselineskip}}
\let\oldexists\exists
\renewcommand\exists{\oldexists~}
\let\oldL\L
\renewcommand\L{\mathfrak{L}}
\makeatletter
\newcommand{\tpitchfork}{%
  \vbox{
    \baselineskip\z@skip
    \lineskip-.52ex
    \lineskiplimit\maxdimen
    \m@th
    \ialign{##\crcr\hidewidth\smash{$-$}\hidewidth\crcr$\pitchfork$\crcr}
  }%
}
\makeatother
\newcommand{\bd}{\partial}
\newcommand{\lang}{\begin{picture}(5,7)
\put(1.1,2.5){\rotatebox{45}{\line(1,0){6.0}}}
\put(1.1,2.5){\rotatebox{315}{\line(1,0){6.0}}}
\end{picture}}
\newcommand{\rang}{\begin{picture}(5,7)
\put(.1,2.5){\rotatebox{135}{\line(1,0){6.0}}}
\put(.1,2.5){\rotatebox{225}{\line(1,0){6.0}}}
\end{picture}}
\DeclareMathOperator{\id}{id}
\DeclareMathOperator{\im}{Im}
\DeclareMathOperator{\grap}{graph}
\DeclareMathOperator{\codim}{codim}
\DeclareMathOperator{\supp}{supp}
\DeclareMathOperator{\inter}{Int}
\DeclareMathOperator{\sign}{sign}
\DeclareMathOperator{\sgn}{sgn}
\DeclareMathOperator{\indx}{ind}
\DeclareMathOperator{\alt}{Alt}
\DeclareMathOperator{\Aut}{Aut}
\DeclareMathOperator{\trace}{trace}
\DeclareMathOperator{\ad}{ad}
\DeclareMathOperator{\End}{End}
\DeclareMathOperator{\Ad}{Ad}
\DeclareMathOperator{\Lie}{Lie}
\DeclareMathOperator{\spn}{span}
\DeclareMathOperator{\dv}{div}
\DeclareMathOperator{\grad}{grad}
\newcommand*\myhrulefill{%
   \leavevmode\leaders\hrule depth-2pt height 2.4pt\hfill\kern0pt}
\newcommand\niceending[1]{%
  \begin{center}%
    \LARGE \myhrulefill \hspace{0.2cm} #1 \hspace{0.2cm} \myhrulefill%
  \end{center}}
\newcommand*\sectionend{\niceending{\decofourleft\decofourright}}
\newcommand*\subsectionend{\niceending{\decosix}}
\def\upint{\mathchoice%
    {\mkern13mu\overline{\vphantom{\intop}\mkern7mu}\mkern-20mu}%
    {\mkern7mu\overline{\vphantom{\intop}\mkern7mu}\mkern-14mu}%
    {\mkern7mu\overline{\vphantom{\intop}\mkern7mu}\mkern-14mu}%
    {\mkern7mu\overline{\vphantom{\intop}\mkern7mu}\mkern-14mu}%
  \int}
\def\lowint{\mkern3mu\underline{\vphantom{\intop}\mkern7mu}\mkern-10mu\int}
%
%--------Hypersetup--------
%
\hypersetup{
    colorlinks,
    citecolor=black,
    filecolor=black,
    linkcolor=blue,
    urlcolor=black
}
%
%--------Solution--------
%
\newenvironment{solution}
  {\begin{proof}[Solution]}
  {\end{proof}}
%
%--------Graphics--------
%
%\graphicspath{ {images/} }

\begin{document}
\author{Jeffrey Jiang}
\title{The Rising Sea: Categories and Sheaves}
\maketitle

These are some notes + exercises I've compiled working through the first $2$ chapters of Ravi Vakil's \emph{The Rising Sea}, with the main purpose being to gain some familiarity and comfort with categories and sheaves.	
%
\section{Category Theory}
%
\begin{defn}
A \ib{category} $\mathscr{C}$ is a collection\footnote{Loosely speaking; there's some set-theoretic issues here, but it's not that important for us} of \ib{objects}, denoted $\mathsf{Ob}(\mathscr{C})$ and a collection\footnote{Again, ignoring set-theoretic problems} \ib{morphisms} $\hom(A,B)$\footnote{Vikhil uses $\mathsf{Mor}$, but we'll use the more standard notation of $\hom$} for every pair of objects $A,B \in \mathsf{Ob}(\mathscr{C})$ satisfying the following axioms:
\begin{enumerate}
\item Given morphisms $f: A \to B$ and $g: B \to C$, there is a unique map $g \circ f: A \to C$ that makes the following diagram commute
$$\xymatrix{
A \ar@/_1pc/[rr]_{g \circ f}\ar[r]^f & B \ar[r]^g & C
}$$
\item For every object $A \in \mathsf{Ob}(\mathscr{C})$, there exists an \ib{identity morphism} $\id_A \in \hom(A,A)$ such that for any morphisms $f: A \to B$ and $g: C \to A$, we have that $\id_A \circ f = f$ and $g \circ \id_A = g$
\end{enumerate}
A morphism $f: A \to B$ is an \ib{isomorphism} is there exists a morphism $g: B \to A$ such that $f \circ g = \id_B$ and $g \circ f = \id_A$. We then call $g$ the \ib{inverse} to $f$. Isomorphisms $A \to A$ are called \ib{automorphisms} of $A$.
\end{defn}
%
\begin{exmp}
The category of sets, often denoted $\mathsf{Set}$ has sets as its objects, and maps of sets as its morphisms.
\end{exmp}
%
\begin{exmp}
Vector spaces over a field $\F$ also form a category, denoted $\mathsf{Vec}_\F$, where the objects are $\F$-vector spaces, and the objects are $\F$-linear maps.
\end{exmp}
%
\begin{exer}
Let $A$ be an object of a category $\mathscr{C}$. Show that the automorphisms of $\hom(A,A)$ form a group, called the \ib{Automorphism group} of $A$. Show that two isomorphisc objects in $\mathscr{C}$ have isomorphic automorphism groups.
\end{exer}
%
\begin{proof}
Verifying that $\Aut(A)$ is a group is mainly an exercise in definition chasing. Associativity comes from the category axioms, the identity element is the identity morphism, and inverses exist by the definition of the automorphism group. 

For the second part, let $A,B \in \mathsf{Ob}(\mathscr{C})$ be isomorphic, with $f: A \to B$ an isomorphism. We then define a map $f^*: \Aut(B) \to \Aut(A)$ where $f^*\sigma = f\inv \circ \sigma \circ f$. This is clearly a group homomorphism, and is an isomorphism with inverse given by $(f\inv)^*$.
\end{proof}
%
Now that we have categories, the natural thing to study are maps of categories.
%
\begin{defn}
A (covariant) \ib{functor} $\mathcal{F}$ from a category $\mathscr{C}$ to another category $\mathscr{D}$ assigns each object $A \in \mathsf{Ob}(\mathscr{C})$ an object $\mathcal{F}(A) \in \mathsf{Ob}(\mathscr{D})$ and to each map $f:A \to B$ in $\mathscr{C}$ a map $\mathcal{F}(f) : \mathcal{F}(A) \to \mathcal{F}(B)$ such that $\mathcal{F}$ respects composition, i.e.
$$\mathcal{F}(f \circ g) = \mathcal{F}(f) \circ \mathcal{F}(g) $$
a \ib{contravariant functor} can be defined similarly, except it reverses the arrows, i.e. $\mathcal{F}(f)$ is now a map $B \to A$, rather than $A \to B$.
\end{defn}
%
\begin{exmp}
For mathematical objects that are just sets with extra structure (e.g. vector spaces, groups, rings, etc), the \ib{forgetful functor} is the functor that takes each object to its underlying set, and each map to itself (thought of as a map of sets). Categories that admit a forgetful functor into $\mathsf{Set}$ are called \ib{concrete categories}.
\end{exmp}
%
\begin{exmp}[\ib{The functor of points}]
For a category $\mathscr{C}$, fix an object $A \in \mathsf{Ob}(\mathscr{C})$. We use this to define the functor $\mathcal{F}_A: \mathscr{C} \to \mathsf{Set}$, where for $B \in \mathsf{Ob}(\mathscr{C})$, we let $\mathcal{F}(B) = \hom(A,B)$ and for $f: B \to C$, we let $\mathcal{F}_A(f): \hom(A,B) \to \hom(A,C)$ be the map where $\mathcal{F}_A(f)(g) = f \circ g$.
\end{exmp}
Like functions, we can compose functors $\mathcal{F}: \mathscr{A} \to \mathscr{B}$ and $\mathcal{G}:  \mathscr{B} \to \mathscr{C}$ to obtain $\mathcal{G} \circ \mathcal{F}: \mathscr{A} \to \mathscr{C}$, where for $A \in \mathsf{Ob}(\mathscr{A})$, we have that $\mathcal{G} \circ \mathcal{F}(A) = \mathcal{G}(\mathcal{F}(A))$, and the same thing for morphisms in $\mathscr{A}$. Also like functions, we have notions of injectivity and surjectivity.
%
\begin{defn}
A covariant functor $\mathcal{F}: \mathscr{C} \to \mathscr{D}$ is \ib{faithful} if the induced map $\hom_{\mathscr{C}}(A,B) \to \hom_{\mathscr{D}}(\mathcal{F}(A),\mathcal{F}(B))$ is injective and \ib{full} if it surjective.
\end{defn}
%
\begin{exmp}
The forgetful functor $\mathsf{Vec}_k \to \mathsf{Set}$ is not full, since there are more maps of sets than there are maps of vector spaces, since an element of $\hom_{\mathsf{Set}}(V,W)$ need not be linear. However, the ``inclusion" functor $i: \mathsf{Ab} \to \mathsf{Grp}$ from abelian groups into groups is full. Given two abelian groups $G$ and $H$, we clearly have that $\hom_{\mathsf{Ab}}(G,H) = \hom_{\mathsf{Grp}}(G,H)$, so we have that $i$ is a faithful functor as well.
\end{exmp}
Functors in a lot of ways act just like functions, but there's some more things we can do with them. For example, it some sense, we can have maps between functors.
\begin{defn}
Given covariant functors $\mathcal{F},\mathcal{G}: \mathscr{A} \to \mathscr{B}$, a \ib{natural transformation} $\mathcal{F} \to \mathcal{G}$ assigns each object $A \in \mathsf{Ob}(\mathscr{A})$ a morphism $m_A : \mathcal{F}(A) \to \mathcal{G}(A)$, such that for every morphism $f: A \to B$ in $\mathscr{A}$, the following diagram commutes
$$\xymatrix{
\mathcal{F}(A) \ar[r]^{\mathcal{F}(f)} \ar[d]_{m_A} & \mathcal{F}(B) \ar[d]^{m_B} \\
\mathcal{G}(A) \ar[r]_{\mathcal{G}(f)} & \mathcal{G}(B)
}$$
a \ib{natural isomorphism} is when all the given morphisms $m_A$ are isomorphisms.
\end{defn}
%
\begin{exmp}
A trivial example of a natural transformation between $\mathcal{F} \to \mathcal{G}$ assigns the zero map $z:\mathcal{F}(A) \to \mathcal{G}(A)$ for every object $A$. Such a zero map only exists in some categories, such as $\mathsf{Vec}_k$ and $\mathsf{Grp}$.
\end{exmp}
This gives a rigorous definition for the words ``canonical" and ``natural" that get thrown around a bit too often. The prototypical example for this idea is the natural isomorphism from a finite dimensional vector space to its double dual.
%
\begin{exer}
Let $\mathcal{D}: \mathsf{Vec}_k \to \mathsf{Vec}_k$ be the functor that maps each $k$-vector space $V$ to its dual space $V^*$ of linear functions $V \to k$ and maps a linear map $A: V \to W$ to its pullback (sometimes called the transpose) $A^*: W^* \to V^*$. Show that the double dual functor $\mathcal{D} \circ \mathcal{D}$ is naturally isomorphic to the identity functor $\id$.
\end{exer}
%
\begin{proof}
For a vector $v$ in a vector space $V$, define the map $\xi_v: V^* \to k$ by $\xi_v(\omega) = \omega(v)$. The let $\Xi_V: V \to V^{**}$ be the map that sends $v \mapsto \xi_v$. We claim that the morphisms $\Xi_V$ define a natural isomorphism from $\mathcal{D} \circ \mathcal{D}$ to $\id$. We first show that $\Xi_V$ defines an isomorphism. Since $V$ and $V^{**}$ are the same dimension, it suffices to check that $\Xi_V$ has trivial kernel. Suppose $v \mapsto \xi_v = 0$. Then $\omega(v) = 0$ for all $\omega \in V^*$, which is only true when $v = 0$. Therefore, $\Xi_V$ is an isomorphism for every $V$. Showing that the $\Xi_V$ define a natural isomorphism now amounts to showing that the following diagram commutes
$$\xymatrix{
V \ar[r]^A \ar[d]_{\Xi_V} & W \ar[d]^{\Xi_W} \\
V^{**} \ar[r]_{A^{**}} & W^{**}
}$$
which amounts to showing that $\Xi_W \circ A = A^{**} \circ \Xi_V$. Let $v \in V$ and $\omega \in W^*$. Then we compute
\begin{align*}
(\Xi_W \circ A)(v)(\omega) &= \Xi_W(Av)(\omega) \\
&= \xi_{Av}(\omega) \\
&= \omega(Av)
\end{align*}
We also compute
\begin{align*}
(A^{**} \circ \Xi_V)(v)(\omega) &= A^{**}\xi_v(\omega) \\
&= \xi_v(A^{*}\omega) \\
&= A^{*}\omega(v) \\
&= \omega(Av)
\end{align*}
So we have given a natural isomorphism $\mathcal{D} \circ \mathcal{D} \to \id$
\end{proof}
%
It's also somewhat easy in this language why there is no natural isomorphism from a vector space to its dual. When you saw it, there was most likely some hand-waving about how the choice of a basis made the isomorphism unnatural, so we can make this rigorous now.
%
\begin{prop}
There exists no natural isomorphism from the dual functor $\mathcal{D}$ to the identity functor $\id$
\end{prop}
%
\begin{proof}
%
Suppose such a natural isomorphism existed, and assigned each vector space an isomorphism $\varphi_V: V \to \V^*$ such that the following diagram commutes for any linear map $A: V \to W$.
$$\xymatrix{
V \ar[d]_{\varphi_V}\ar[r]^A & W \ar[d]^{\varphi_W} \\
V & W \ar[l]^{A^*}
} $$
If we let $A$ be the zero map, we have that $A^* \circ \varphi_W \circ A = 0$, so it cannot be $\varphi_V$.
\end{proof}
%
One product from category theory that ends up being extremely useful is the notion of a \ib{universal property}. One example you may have seen before is the universal property of a product-- Given two objects $A,B$ in some category $\mathscr{C}$, their product, denoted $A \times B \in \mathsf{Ob}(\mathscr{C})$ is (up to unique isomorphism) the unique object with maps $\pi_A: A\times B \to A$ and $\pi_B : A \times B \to B$ such that given any pair of maps $f: P \to A$ and $g: P \to B$ factor uniquely through $A \times B$, i.e. there exists a unique map $f \times g: P \to A\times B$ such that the following diagram commutes
$$\xymatrix{
P \ar[dr]_{f \times g} \ar[d]_g \ar[r]^f & A \\
B & A \times B \ar[l]^{\pi_B} \ar[u]^{\pi_A}
}$$
Some other useful objects defined by universal properties
%
\begin{defn}
An \ib{initial object}  $I$ in a category $\mathscr{C}$ if there exists exactly one map $I \to A$ for every $A \in \mathsf{Ob}(\mathscr{C})$. A \ib{final object} is an object $F$ in which there exactly one map $A \to F$ for every object $A$. An object $Z$ is a \ib{zero object} if it is both an initial and final object.
\end{defn}
%
\begin{exer}
Show any two initial objects are uniquely isomorphic. Show any two final objects are uniquely isomorphic
\end{exer}
%
\begin{proof}
Let $A,B$ be initial objects. We note that the definition of an initial object implies that the only map $A \to A$ and $B \to B$ must be $\id_A$ and $\id_B$ respectively. Therefore, the unique maps $A \to B$ and $B \to A$ must compose to identity, so they are isomorphisms.

The same proof applies to final objects. For final objects the unique maps $A \to A$ and $B \to B$ are necessarily the identity maps, and the unique maps $A \to B$ and $B \to A$ must compose to identity.
\end{proof}
For concreteness, we should determine what these some of objects are
\begin{exer}
What are the initial/final objects in $\mathsf{Set},\mathsf{Ring}$\footnote{Since this book is for algebraic geometry, all rings are commutative and unital. Ring maps are required to map $1 \mapsto 1$} and $\mathsf{Top}$?
\end{exer}
%
\begin{proof}[Solution]\enumbreak
\begin{enumerate}
\item The initial object for $\mathsf{Set}$ is the empty set. Given any set $S$, we have a unique map $\emptyset \to S$ (the empty map). The final object is the single point set $*$. Given any set $S$, there exists only a single map to $*$, namely the map that takes all of $S$ to the point. We note that the empty set cannot be a final object, since we cannot map a nonempty set to an empty set.
\item The initial object in $\mathsf{Ring}$ is the integers $\Z$. Given any commutative unital ring $R$ (which from now on we'll just say ring), the unique map $\Z \to R$ is entirely determined by the map $1 \mapsto 1$ since $1$ generates $\Z$ as an abelian group. The final object is the zero ring $0 = 1$, where the unique map $R \to 0$ is the map that sends everything to $0$.
\item The initial and final objects for $\mathsf{Top}$ are the same as for $\mathsf{Set}$. We note that the empty set and a single point set have unique topologies, so we do not need to specify a topology.
\end{enumerate}
\end{proof}
One reason that universal properties are nice is that they give an extremely helpful way in proving that some object is the one we desire -- by showing it satisfies the universal property. Given an arbitrary set $P$, how can I conclude that it is the product $A \times B$? We can look for an explicit isomorphism, which can be difficult, or we can simply show that it satisfies the same universal property as the product. Another good example of a universal property comes from an important concept in algebraic geometry -- the localization of a ring.
\begin{exmp}[\ib{Localization of a ring}]
Given a ring $R$ and a multiplicative subset $S \subset R$ (a set closed under multiplication that contains $1$). We can then define the ring $S\inv R$ to be the set of formal fractions $\set{r/s ~:~ r \in R, s \in S}$ modulo the equivalence relation $\sim$ where $r/s \sim p/q$ if and only if there exists $t \in S$ such that $t(qr - sp) = 0$\footnote{This might look strange if you compare it to the fractions you know in $\Q$, but special care needs to be taken in the case that $R$ contains zero divisors}. Addition and multiplication of fractions is exactly the same as in $\Q$, namely $r/s + p/q = (rq + ps)/pq$ and $r/s \cdot p/q = rp/sq$. We then have a canonical map $R \to S\inv R$ where $r \mapsto r/1$
\end{exmp}
%
\begin{exer}
Show the canonical map $R \to S\inv R$ is injective if and only if $S$ contains no zero divisors.
\end{exer}
%
\begin{proof}
Suppose there exists two distinct elements $p,q$ that map to the same element, i.e. $p/1 \sim q/1$. This means that there exists some $s \in S$ such that $s(p-q) = 0$, which is true if and only if $s$ is a zero divisor for the nonzero element $p-q$.
\end{proof}
%
\begin{exer}
Show that $S\inv R$ satisfies the following universal property: $S\inv R$ is initial among $R$-algebras $A$ where every element of $S$ is mapped to a invertible element. In other words any map $R \to A$ in which every element is mapped to an invertible element factors uniquely through the map $R \to S\inv R$.
\end{exer}
%
\begin{proof}
Let $\varphi : R \to A$ be such a map where every element of $S$ maps to an invertible element. The we want to find a map $\tilde{\varphi}: S\inv R \to A$ such that the following diagram commutes
$$\xymatrix{
R \ar[d]_{\iota}\ar[r]^{\varphi} & A \\
S\inv R \ar[ur]_{\tilde{\varphi}}
}$$
where $\iota : R \to S\inv R$ is the canonical map. We note that in order for the diagram to commute, we must necessarily have that $\tilde{\varphi}(r/1) = \varphi(r)$ for every $r \in R$. Therefore, the only possible mapping for $\tilde{\varphi}$ must be $\tilde{\varphi}(r/s) = \varphi(r) / \varphi(s)$, which is possible since $\varphi(s)$ is invertible, so we have found our unique map.
\end{proof}
You can localization for $R$-modules $M$ as well. Let's define it in terms of a universal property this time. Let $S\inv M$ be the $R$-module equipped with the map $\varphi : M \to S\inv M$ where any map $f: M \to N$ such that scalar multiplication $M_s: N \to N$ is an isomorphism factors through $S\inv M$ as a unique map $\tilde{f}: S\inv M \to N$, i.e. the following diagram commutes
$$\xymatrix{
M \ar[d]_{\varphi}\ar[r]^f & N \\
S\inv M \ar[ur]_{\tilde{f}}
}$$
%
\begin{exer}
Prove that the localization $(S\inv M, \varphi)$ exists.
\end{exer}
%
\begin{proof}
Define the localization $S\inv M$ similarly to $S\inv R$ as the set
$$\set{\frac{m}{s} ~:~ m \in M s \in S} / \sim $$
modulo the relation $\sim$ where $m/s \sim n/p$ if there exists $t \in S$ such that $t(mp - ns) = 0$, and let $\varphi$ be the map $m \mapsto m / 1$. We claim that this satisfies the universal property given above. Let $f: M \to N$ be a map of modules where $S$ acts on $N$ by isomorphisms. Then define $\tilde{f}: S\inv M \to N$ by $\tilde{f}(m/s) = 1/s \cdot f(m)$, where $1/s$ is the inverse to the multiplication map $m_s: R \to R$, which is defined since scalar multiplication by $s$ defines an isomorphism $N \to N$. It is clear that the diagram commutes, so the set and map we gave satisfies the universal property.
\end{proof}
%
Another example is the tensor product $\otimes$, where given $R$-modules $M$ and $N$, we can form $M \otimes_R N$ as the set of sums formal symbols $m \otimes n$ where $m \in M$ and $n \in N$ where $\otimes$ is bilinear, i.e. $(am_1 + bm_2) \otimes n = am_1 \otimes + bm_2 \otimes n$ and $m \otimes (an_1 + bn_2) = am\otimes n_1 + bm\otimes n_2$.
%
\begin{exer}
Show that $Z/10\Z \otimes_\Z Z/12\Z \cong Z/2\Z$.
\end{exer}
%
\begin{proof}
Let $[a]_{10}$ denote the equivalence class of $a \in Z$ in $\Z/10\Z$ and define $[a]_{12}$ similarly. Then define the map $\varphi: \Z/10\Z \otimes_\Z \Z/12\Z \to \Z/2\Z$ by $[a]_{10} \otimes [b]_{12} \mapsto [ab]_2$ and extending linearly to sums. This is clearly surjective and $\Z$-linear, so to show that $\varphi$ is an isomorphism, we show that the kernel is trivial. To show this, it suffices to check elements of the form $[a]_{10} \otimes [b]_{12}$. Suppose we have $[a]_{10} \otimes [b]_{12} \mapsto 0$. Noting that $[a]_{10} = a[1]_{10}$, and the same for $[b]_{12}$. Therefore, we have that $[a]_{10} \otimes [b]_{12} = ab([1]_{10} \otimes [1]_{12})$. Therefore in order for $\varphi([a]_{10} \otimes [b]_{12}) = 0$, we must have $ab = 0$, since $[1]_{10} \otimes [1]_{12} \mapsto [1]_2$. Therefore, $[a]_{10} \otimes [b]_{12} = 0$, so the kernel is trivial.
\end{proof}
%
\begin{exer}
Fix an $R$-module $N$. Define a functor $\mathcal{N}: \mathsf{Mod}_R \to \mathsf{Mod}_R$ by $\mathcal{N}(M) = M \otimes_R N$, and for any map $\varphi : A \to B$, let $\mathcal{N}(\varphi) : A\otimes_R N \to B\otimes_R N$ be the map defined by $\mathcal{N}(\varphi)(a \otimes n) = \varphi(a) \otimes n$. Show that $\mathcal{N}$ is indeed a covariant functor, and that it is \ib{right-exact}, i.e. if we are given a short exact sequence of $R$-modules
$$0 \to A \to B \to C \to 0 $$
the corresponding sequence
$$0 \to A \otimes_R N \to B \otimes_R N \to C \otimes_R N $$
is also exact.
\end{exer}
%
\begin{proof}
To show that $\mathcal{N}$ defines a functor, all we need to show is that it respects composition. Let $\varphi: A \to B$ and $\psi: B \to C$. Then we need to show that $\mathcal{N}(\psi \circ \varphi) = \mathcal{N}(\psi) \circ \mathcal{N}(\varphi)$. To show this, it suffices to show that they agree on elements of the form $a \otimes n$. We compute
$$ \mathcal{N}(\psi \circ \varphi)(a \otimes n) = (\psi \circ \varphi)(a) \otimes n = \mathcal{N}(\psi \circ \varphi)(a \otimes n) $$
so $\mathcal{N}$ is a functor.

We now show that $\mathcal{N}$ is right exact. Let 
$$\xymatrix{
0 \ar[r] & A \ar[r]^\varphi & B \ar[r]^\psi & C \ar[r] & 0
}$$
be exact, i.e. $\ker\psi = \im\varphi$, $\varphi$ is injective, and $\varphi$ is surjective. We want to show that 
$$\xymatrix{
0 \ar[r] & A \otimes_R N \ar[r]^{\mathcal{N}(\varphi)} & B \otimes_R N \ar[r]^{\mathcal{N}(\psi)} & C \otimes_R N \ar[r] & 0
}$$
Is also exact, i.e. $\mathcal{N}(\varphi)$ is injective, $\ker\mathcal{N}(\psi) = \im\mathcal{N}(\varphi)$, and $\mathcal{N}(\psi)$ is surjective. We note that if $\mathcal{N}(\varphi)(a \otimes n) = 0$, then this means that $\varphi(a) \otimes n = 0$, which means either $\varphi(a) = 0$ or $n = 0$. Since $\varphi$ is injective, this implies that either $a$ or $n$ is $0$, so $a \otimes n = 0$. Therefore, $\mathcal{N}(\varphi)$ is also injective. Next, we want to show that $\mathcal{N}(\varphi)$ surjects onto $\ker\mathcal{N}(\psi)$. To do this, we first characterize the elements in $\ker\mathcal{N}(\psi)$. Suppose $\mathcal{N}(\psi)(b \otimes n) = \psi(b) \otimes n = 0$. Then we must have that either $\psi(b) = 0$ or $n = 0$. Therefore, the kernel of $\mathcal{N}(\psi)$ is exactly $\ker\psi \otimes_R N$. We note that the image of $\mathcal{N}(\varphi)$ is exactly $\im\varphi \otimes N$, and since the original sequence is exact, this gives us that $\im\mathcal{N}(\varphi) = \ker\mathcal{N}(\psi)$. Finally, we must show that $\mathcal{N}(\psi)$ is surjective.  We note that the image of $\mathcal{N}(\psi)$ is exactly $\im\psi \otimes_R N = C \otimes_R N$ since $\psi$ was surjective. Therefore, the sequence is exact.
\end{proof}
The characterization we gave for the tensor product $A \otimes B$, while not wrong, is pretty inelegant, and obfuscates the real reason we like tensor products. It is much better to define the tensor product in terms of the universal property it satisfies. In this case, given $R$-modules $A,B$, the tensor product $A \otimes B$ is an $R$-module equipped with a bilinear map $\varphi: A\times B \to A \otimes B$  such that for any bilinear map $\psi: A \times B \to C$, it factors uniquely as a linear map $A \otimes B$, i.e. the following diagram commutes
$$\xymatrix{
A\times B \ar[r]^\psi \ar[d]_{\varphi} & C \\
A \otimes B \ar[ur]
}$$  
So the tensor product is another $R$-module in which linear maps are equivalent to bilinear maps out of $A \times B$. The construction we gave above equivalent, with the map $\varphi$ being given by the mapping $(a,b) \mapsto a \otimes b$.
%
\begin{exer}\enumbreak
\begin{enumerate}
\item Let $M$ be an $A$ module, and let $\varphi : A \to B$ be a ring homomorphism. GIve $B \otimes_A M$ the structure of a $B$-module. Show that this defines a functor $\mathsf{Mod}_A \to \mathsf{Mod}_B$.
\item Furthermore, if we are given another ring homomorphism $\rho : A \to C$, show that we can endow $B \otimes_A C$ the structure of a ring.
\end{enumerate}
\end{exer}
%
\begin{proof}\enumbreak
\begin{enumerate}
\item We note that the homomorphism $\varphi: A \to B$ gives $B$ the structure of an $A$-module where the scalar multiplication is given by $a \cdot b = \varphi(a)b$, so it makes sense to construct $B \otimes_A M$. To make $B \otimes_A M$ a $B$-module, we just need to specify a scalar multiplication by $B$. Let $b \otimes m \in B \otimes_A M$, and let $\lambda \in B$. Let 
$$\lambda \cdot b \otimes m = \lambda b \otimes m$$
and extending linearly to sums. By definition this distributes over the addition of $B \otimes_A M$ as an $A$-module, so this makes it a $B$-module as well. We note by the previous exercise, tensoring with a fixed $A$-module (in this case $B$), defines an functor.
\begin{rem*}
This process is commonly referred to as \ib{extension of scalars}, especially when the map $\varphi$ is like an inclusion, e.h. $\R \hookrightarrow \C$. In that case, this process takes a real vector space and complexifies it into a complex vector space.
\end{rem*}
\item Let addition on $B \otimes_A C$ be the standard addition as $A$-modules. Then we define multiplication as 
$$(b_1\otimes c_1)(b_2 \otimes c_2) = b_1b_2 \otimes  c_1c_2$$
and extending linearly to sums, which covers distributivity. In addition, multiplication is commutative since $B$ and $C$ are commutative, so this forms a ring.
\end{enumerate}
\end{proof}
%
\begin{exer}
Let $S$ be a multiplicative subset of $A$, and let $M$ be an $A$-modules. Describe a natural isomorphism $(S\inv A) \otimes_A M \cong S\inv M$.
\end{exer}
%
\begin{proof}
We already have that the assignment $M \mapsto (S\inv A) \otimes_A M$ defines a functor, and it is simple to check that the assignment $M \mapsto S\inv M$ also defines a functor, so we are looking for isomorphisms $\varphi_M : (S\inv A)\otimes_A M \to S\inv M$ such that the following diagram commutes for any $A$-module homomorphism $\psi : M \to  N$
$$\xymatrix{
(S\inv A) \otimes_A M \ar[d]_{\varphi_M }\ar[r]^{\tilde{\psi}} & (S\inv A) \otimes_A  N \ar[d]^{\varphi_N} \\
S\inv M \ar[r]^{\bar{\psi}} & S\inv N
}$$
Where $\tilde{\psi}$ denotes the map where $r/s \otimes m \mapsto r/s \otimes \psi(m)$ and $\bar{\psi}$ denotes the map where $m/s \mapsto \psi(m)/s$. Define $\varphi_M (S\inv A) \otimes_A \to S\inv M$ by
$$\frac{r}{s} \otimes m \mapsto \frac{rm}{s} $$
we note that the kernel is trivial, since $rm/s = 0$ if and only if $r = 0$ or $m = 0$. In addition, the map is surjective, since we have that $1/s \otimes m \mapsto m/s$, so this defines an isomorphism. Finally, to show that the diagram commutes, we want to show that $\varphi_N \circ \tilde{\psi} = \bar{\psi} \circ \varphi_M$. We compute
\begin{align*}
(\varphi_N \circ \tilde{\psi})(r/s \otimes m) &= \varphi_N(r/s \otimes \psi(m)) \\
&= r\psi(m)/s \\
(\bar{\psi} \circ \varphi_M)(r/s \otimes m) &= \tilde{psi}(rm/s) \\
&=  \psi(rm) /s \\
&= r\psi(m)/s
\end{align*}
So the diagram commutes, and we have specified a natural isomorphism.
\end{proof}
%
\begin{exmp}[\ib{Fibered products}]

\end{exmp}
%
\end{document}