\documentclass[psamsfonts]{amsart}
%
%-------Packages---------
%
\usepackage[h margin=1 in, v margin=1 in]{geometry}
\usepackage{amssymb,amsfonts}
\usepackage[all,arc]{xy}
\usepackage{tikz-cd}
\usepackage{enumerate}
\usepackage{mathrsfs}
\usepackage{amsthm}
\usepackage{mathpazo}
\usepackage{yfonts}
\usepackage{enumitem}
\usepackage{mathrsfs}
\usepackage{fourier-orns}
\usepackage[all]{xy}
\usepackage{hyperref}
\usepackage{cite}
\usepackage{url}
\usepackage{mathtools}
\usepackage{graphicx}
\usepackage{pdfsync}
\usepackage{mathdots}
\usepackage{calligra}
%
\usepackage{tgpagella}
\usepackage[T1]{fontenc}
%
\usepackage{listings}
\usepackage{color}

\definecolor{dkgreen}{rgb}{0,0.6,0}
\definecolor{gray}{rgb}{0.5,0.5,0.5}
\definecolor{mauve}{rgb}{0.58,0,0.82}

\lstset{frame=tb,
  language=Matlab,
  aboveskip=3mm,
  belowskip=3mm,
  showstringspaces=false,
  columns=flexible,
  basicstyle={\small\ttfamily},
  numbers=none,
  numberstyle=\tiny\color{gray},
  keywordstyle=\color{blue},
  commentstyle=\color{dkgreen},
  stringstyle=\color{mauve},
  breaklines=true,
  breakatwhitespace=true,
  tabsize=3
  }
%
%--------Theorem Environments--------
%
\newtheorem{thm}{Theorem}[section]
\newtheorem*{thm*}{Theorem}
\newtheorem{cor}[thm]{Corollary}
\newtheorem{prop}[thm]{Proposition}
\newtheorem{lem}[thm]{Lemma}
\newtheorem*{lem*}{Lemma}
\newtheorem{conj}[thm]{Conjecture}
\newtheorem*{quest}{Question}
%
\theoremstyle{definition}
\newtheorem{defn}[thm]{Definition}
\newtheorem*{defn*}{Definition}
\newtheorem{defns}[thm]{Definitions}
\newtheorem{con}[thm]{Construction}
\newtheorem{exmp}[thm]{Example}
\newtheorem{exmps}[thm]{Examples}
\newtheorem{notn}[thm]{Notation}
\newtheorem{notns}[thm]{Notations}
\newtheorem{addm}[thm]{Addendum}
\newtheorem{exer}[thm]{Exercise}
\newtheorem*{TODO}{\ib{TODO}}
%
\theoremstyle{remark}
\newtheorem{rem}[thm]{Remark}
\newtheorem*{claim}{Claim}
\newtheorem*{aside*}{Aside}
\newtheorem*{rem*}{Remark}
\newtheorem*{hint*}{Hint}
\newtheorem*{note}{Note}
\newtheorem{rems}[thm]{Remarks}
\newtheorem{warn}[thm]{Warning}
\newtheorem{sch}[thm]{Scholium}
%
%--------Macros--------
\renewcommand{\qedsymbol}{$\blacksquare$}
\renewcommand{\hom}{\mathsf{Hom}}
\renewcommand{\emptyset}{\varnothing}
\renewcommand{\O}{\mathscr{O}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\ib}[1]{\textbf{\textit{#1}}}
\newcommand{\Q}{\mathbb{Q}}
\newcommand{\Z}{\mathbb{Z}}
\newcommand{\N}{\mathbb{N}}
\newcommand{\C}{\mathbb{C}}
\newcommand{\A}{\mathbb{A}}
\newcommand{\F}{\mathbb{F}}
\newcommand{\M}{\mathcal{M}}
\renewcommand{\S}{\mathbb{S}}
\newcommand{\V}{\vec{v}}
\newcommand{\RP}{\mathbb{RP}}
\newcommand{\CP}{\mathbb{CP}}
\newcommand{\B}{\mathcal{B}}
\newcommand{\GL}{\mathsf{GL}}
\newcommand{\SL}{\mathsf{SL}}
\newcommand{\SP}{\mathsf{SP}}
\newcommand{\SO}{\mathsf{SO}}
\newcommand{\SU}{\mathsf{SU}}
\newcommand{\gl}{\mathfrak{gl}}
\newcommand{\g}{\mathfrak{g}}
\newcommand{\inv}{^{-1}}
\newcommand{\bra}[2]{ \left[ #1, #2 \right] }
\newcommand{\ind}{\lambda \in \Lambda}
\newcommand{\set}[1]{\left\lbrace #1 \right\rbrace}
\newcommand{\abs}[1]{\left\lvert#1\right\rvert}
\newcommand{\norm}[1]{\left\lVert#1\right\rVert}
\newcommand{\transv}{\mathrel{\text{\tpitchfork}}}
\newcommand{\enumbreak}{\ \\ \vspace{-\baselineskip}}
\let\oldexists\exists
\renewcommand\exists{\oldexists~}
\let\oldL\L
\renewcommand\L{\mathfrak{L}}
\makeatletter
\newcommand{\tpitchfork}{%
  \vbox{
    \baselineskip\z@skip
    \lineskip-.52ex
    \lineskiplimit\maxdimen
    \m@th
    \ialign{##\crcr\hidewidth\smash{$-$}\hidewidth\crcr$\pitchfork$\crcr}
  }%
}
\makeatother
\newcommand{\bd}{\partial}
\newcommand{\lang}{\begin{picture}(5,7)
\put(1.1,2.5){\rotatebox{45}{\line(1,0){6.0}}}
\put(1.1,2.5){\rotatebox{315}{\line(1,0){6.0}}}
\end{picture}}
\newcommand{\rang}{\begin{picture}(5,7)
\put(.1,2.5){\rotatebox{135}{\line(1,0){6.0}}}
\put(.1,2.5){\rotatebox{225}{\line(1,0){6.0}}}
\end{picture}}
\DeclareMathOperator{\id}{id}
\DeclareMathOperator{\im}{Im}
\DeclareMathOperator{\grap}{graph}
\DeclareMathOperator{\codim}{codim}
\DeclareMathOperator{\coker}{coker}
\DeclareMathOperator{\supp}{supp}
\DeclareMathOperator{\inter}{Int}
\DeclareMathOperator{\sign}{sign}
\DeclareMathOperator{\sgn}{sgn}
\DeclareMathOperator{\indx}{ind}
\DeclareMathOperator{\alt}{Alt}
\DeclareMathOperator{\Aut}{Aut}
\DeclareMathOperator{\trace}{trace}
\DeclareMathOperator{\ad}{ad}
\DeclareMathOperator{\End}{End}
\DeclareMathOperator{\Ad}{Ad}
\DeclareMathOperator{\Lie}{Lie}
\DeclareMathOperator{\Cliff}{Cliff}
\DeclareMathOperator{\spn}{span}
\DeclareMathOperator{\dv}{div}
\DeclareMathOperator{\grad}{grad}
\DeclareMathOperator{\Pin}{Pin}
\DeclareMathOperator{\Spin}{Spin}
\DeclareMathOperator{\sheafhom}{\mathscr{H}\text{\kern -3pt {\calligra\large om}}\,}
\newcommand*\myhrulefill{%
   \leavevmode\leaders\hrule depth-2pt height 2.4pt\hfill\kern0pt}
\newcommand\niceending[1]{%
  \begin{center}%
    \LARGE \myhrulefill \hspace{0.2cm} #1 \hspace{0.2cm} \myhrulefill%
  \end{center}}
\newcommand*\sectionend{\niceending{\decofourleft\decofourright}}
\newcommand*\subsectionend{\niceending{\decosix}}
\def\upint{\mathchoice%
    {\mkern13mu\overline{\vphantom{\intop}\mkern7mu}\mkern-20mu}%
    {\mkern7mu\overline{\vphantom{\intop}\mkern7mu}\mkern-14mu}%
    {\mkern7mu\overline{\vphantom{\intop}\mkern7mu}\mkern-14mu}%
    {\mkern7mu\overline{\vphantom{\intop}\mkern7mu}\mkern-14mu}%
  \int}
\def\lowint{\mkern3mu\underline{\vphantom{\intop}\mkern7mu}\mkern-10mu\int}
%
%--------Hypersetup--------
%
\hypersetup{
    colorlinks,
    citecolor=black,
    filecolor=black,
    linkcolor=blue,
    urlcolor=black
}
%
%--------Solution--------
%
\newenvironment{solution}
  {\begin{proof}[Solution]}
  {\end{proof}}
%
%--------Graphics--------
%
%\graphicspath{ {images/} }

\begin{document}
\author{Jeffrey Jiang}
\title{Spin Geometry Conference Course}
\maketitle
%
\setcounter{section}{1}
\section*{Week 1}
%
\begin{exer}
Prove $SL_n(\R)$ and $O(n)$ are manifolds
\end{exer}
%
\begin{exer}
What is the ``shape" of $SL_2(\R)$?
\end{exer}
%
\begin{exer}
Prove that
$$O(2) = \set{\begin{pmatrix}
\cos\theta -\sin\theta \\
\sin\theta \cos\theta
\end{pmatrix}} \cup \set{\begin{pmatrix}
\cos\theta \sin\theta \\
\sin\theta -\cos\theta 
\end{pmatrix}}$$
The first set consists of rotations and the second set consists of reflections. Which rotations commute? Which reflections commute? Do reflections commute with reflections?
\end{exer}
%
\begin{exer}
Investigate $O(3)$. What is it's ``shape?"
\end{exer}
%
\setcounter{section}{2}
%
\setcounter{thm}{0}
%
\section*{Week 2}
\begin{exer}
What is the derivative of $\det$?
\end{exer}
%
\begin{exer}
Explore the exponetial map $\mathfrak{sl}_2(\R) \to SL_2(\R)$
\end{exer}
%
\begin{exer}
Prove that every element of $O(n)$ can be written as the composition of at most $n$ reflections about hyperplanes in $\R^n$.
\end{exer}
%
\begin{proof}
We do this by induction. For $n = 1$, this is obvious, since $O(1) \cong \pm 1$. The assuming that this holds for dimension $n-1$, Let $A \in O(n)$, and let $v \in \R$. We want to construct a hyperplane reflection $R$ such that $RAv = v$, which is obtained by taking $R$ to be the hyperplane reflection about the bisector of $v$ and $Av$. More explicitly, take $R$ to be the hyperplane reflection about the vector 
$$\frac{Av - v}{\norm{Av - v}} $$
which is given by the equation
$$Rw = w - 2 \frac{\langle Av - v, v \rangle}{\langle Av - v, Av - v \rangle}(Av - v) $$
Computing its action on $v$, we get 
\begin{align*}
Rv &= v - 2 \frac{\langle Av - v, v \rangle}{\langle Av - v, Av - v \rangle}(Av - v) \\
&= v - \frac{2\langle Av, v \rangle - 2\langle v, v \rangle}{2 \langle v, v \rangle - 2 \langle Av, v \rangle}(Av - v) \\
&= v + Av -v \\
&= Av
\end{align*}
Then since $R$ is its own inverse (being a reflection), we have that $RAv = v$, so $RAv$ fixes $v$ and its orthogonal complement.
\end{proof}
%
\begin{TODO}
Add motivation for $A^\pm_n$
\end{TODO}
%
\begin{defn}
Define $A^\pm_n$ to be the unital algebra generated by $\R^n$ such that $\xi^2 = \pm 1$. and $\xi\eta = ?~\eta\xi$. Determine the sign of $\eta\xi$. Explore these algebras. Find $A\pm_1$, $A^\pm_2 \ldots$. What are they isomorphic to? Can you identify $O(n)$ as a subgroup?
\end{defn}
%
\setcounter{section}{3}
%
\setcounter{thm}{0}
%
\section*{Week 3}
\begin{exer}
Classify the algebras $A^+_n$ (we messed these up week 2).
\end{exer}
%
\begin{exer}
Prove that 
$$\set{e_{i_1}e_{i_2}\ldots e_{i+k} ~|~ 1 \leq i_1 < i_2 < \ldots < i_k \leq n} $$
is a basis for $A^\pm_n$.
\end{exer}
%
\begin{exer}
Modify the isomorphisms found for $A^-_n$ by choosing $\Z/2\Z$ gradings for the domains and codomains such that the isomorphisms are now isomorphisms as superalgebras.
\end{exer}
%
\begin{exer}
Construct a tensor product for super vector spaces and superalgebras.
\end{exer}
%
\begin{exer}
Explore the ``shape" of the group 
$$G = \langle v ~|~ \norm{v} = 1 \rangle \subset (A_n^-)^\times $$
and the nature of the surjection $G \twoheadrightarrow O(n)$. What is the kernel of this map?
\end{exer}
%
\setcounter{section}{4}
%
\setcounter{thm}{0}
%
\section*{Week 4}
%
\begin{exer}
Define $\varphi : A^\pm_n \to A^\pm_n$ by $\varphi(v) = -v$ and $\varphi(vw) = (wv)$ (i.e. $\varphi$ reverses products), and extending linearly to sums. Does $\varphi(x)\cdot x$ define a norm on $A^\pm_n$?
\end{exer}
%
\begin{exer}
Let $(A, \norm{})$ be a normed $\R$-algebra such that $\norm{ab} \leq \norm{a}\norm{b}$ for all $a,b \in A$. Show that the multiplicative units form an open subset.
\end{exer}
We note that an algebra element $a \in A$ determines a linear map $L_a : A \to A$ by left multiplication, i.e. $L_a(b) = ab$. By fixing a basis for $A$ as a vector space, we get an assignment $a \mapsto M_a$, where $M_a$ is the matrix for $L_a$ in this basis. We claim that an element $a \in A$ is a unit iff $\det M_a \neq 0$. To see this, we note that if $L_a$ is not invertible, then $a$ certainly cannot be, since otherwise $L_{a\inv}$ would be an inverse. For the other direction, we note that if $a$ is not a unit, then $L_a$ is not surjective, since $1_A$ is not in the image. We then claim that this mapping $a \mapsto M_a$ is continuous. Do do this, define a norm on the space of linear maps on $A$ by
$$\norm{M} = \sup_{v \in A} \frac{\norm{Mv}}{\norm{v}} $$
Then given $a,b \in A$, we compute
\begin{align*}
\norm{M_{a-b}} &= \sup_{v \in A} \frac{\norm{(a-b)v}}{\norm{v}} \\
&\leq \sup_{v \in A} \frac{\norm{a-b}\norm{v}}{\norm{v}} \\
&\leq \norm{a-b}
\end{align*}
So as $b \to a$, we have that $\norm{M_{a-b}} \to 0$ as well, so this mapping is continuous. Therefore, the mapping $a \mapsto \det M_a$ is then continuous, which makes the group of units $A^\times$ an open set, being the preimage of the open set $\R - \set{0}$.

One thing to note is that the argument we use to show that $a \mapsto M_a$ is continuous works with any norm such that $\norm{ab} \leq c \norm{a}\norm{b}$ for any constant $c$. Therefore, we have a small lemma regarding finite dimensional algebras with an inner product.
%
\begin{lem*}
Let $A$ be an $n$-dimensional algebra with inner product $\langle \cdot,\cdot\rangle$, and let $\norm{\cdot}$ denote the norm induced by the inner product $\norm{x}^2 = \langle x, x \rangle$. Then for all $xy \in A$, we have 
$$\norm{xy} \leq n^5\abs{\Gamma}\norm{a}\norm{b} $$
where $\Gamma$ denotes the structure constant of maximal magnitude with respect to a fixed orthonormal basis.
\end{lem*}
%
\begin{proof}
Fix a basis $\set{e_i}$ for $A$, and let $c^k_{ij}$ denote the structure constants where
$$e_ie_j = c^k_{ij}e_k $$
Then let $x = a^ie_i$ and $y = b^je_j$. We then compute
\begin{align*}
\norm{xy}^2 &= \langle a^ib^je_ie_j, a^\ell b^m e_\ell e_m \rangle \\
&= \langle a^ib^jc^k_{ij}e_k, a^\ell b^m c^n_{\ell m}e_n \rangle \\
&= a^i a^\ell b^j b^m c^k_{ij} c^n_{\ell m} \langle e_k , e_n \rangle \\
&\leq a^i a^\ell b^j b^m \Gamma^2  n \\
&\leq n^{5/2} \Gamma^2 \norm{a}\norm{b}
\end{align*}
\end{proof}
Because of this, we have that for the Clifford algebras $A^\pm_n$, the mapping from algebra elements to linear maps on the algebra is continuous, regardless of our choice of inner product. We can then use this to define a nicer norm on the Clifford algebras. First fix an arbitrary inner product and denote the induced norm $\norm{\cdot}_1$. Then define 
$$\norm{a} = \sup_{v \in A^{\pm}_n}\frac{\norm{av}_1}{\norm{v}_1} $$
which gives us a submultiplicative norm, so the group of units is an open subset. 

We now want to prove that $G$ is a topological group. To do this, it suffices to show that multiplication and inversion are continuous on $A^\pm_n$. For multiplication, fix $c,d \in A$, and suppose we have $a,b \in A$ such that
$$\norm{a - c} < \varepsilon \qquad \norm{b -d } < \varepsilon $$
for small $\varepsilon > 0$. Then we have 
\begin{align*}
\norm{ab - cd} &= \norm{ab - ad + ad - cd} \\
&= \norm{a(b-d) + (a-c)d} \\
&\leq \norm{a(b-d)} + \norm{(a-c)d} \\
&\leq \norm{a}\norm{b-d} + \norm{a-c}\norm{d} \\
&\leq (\norm{a} + \norm{d})\varepsilon \\
& \leq (\norm{a - c + c} + \norm{d})\varepsilon \\
&\leq (\norm{a - c} + \norm{c} + \norm{d})\varepsilon \\
&\leq (\varepsilon + \norm{c} + \norm{d})\varepsilon
\end{align*}
so multiplication is continuous at $(c,d)$. 
%
\begin{TODO}
Show inversion is continuous
\end{TODO}
%
\begin{exer}
An algebra $A$ is called a \ib{matrix algebra} if there exists an isomorphism $A \cong \End(V)$ for some vector space $V$. Which $A^\pm_n$ are matrix algebras?
\end{exer}
We explore what it means for $A^\pm_n$ to be a matrix algebra. We have that the isomorphism $\varphi: A^\pm_n \to \End(V)$ induces a Clifford module structure on $V$, where the action on $V$ is exactly $a \cdot v = \varphi(a)v$. What does $\varphi$ being an isomorphism imply about the module structure on $V$? We note that there cannot exist any invariant subspaces of $V$ under that action, since there always exists an endomorphism of $V$ that moves a subspace off of itself. Therefore, there cannot exist any $A^\pm_n$-submodules of $V$. Therefore, for $A^\pm_n$ to be a matrix algebra, there certainly must exist an irreducible $A^\pm_n$-module $V$.

From the universal property we laid out below, we have that out map $A^\pm_n \to \End(V)$ is equivalent data to a map $j: (V, b) \to \End(V)$ satisfying the relation $j(v)^2 = \pm b(v,v)\id_V$
%
\begin{exer}
Given a unital associative algebra $A$ and left $A$-modules $M$ and $N$, how would you form the direct sum? Can you tensor them? What if $A$ was a super algebra and $M,N$ super vector spaces?
\end{exer}
%
\begin{exer}
Let $V$ be a vector space and $b : V \times V \to V$ a bilinear form. We want to construct the Clifford algebra $\Cliff(V,b)$ as the ``best" associative unital $\R$-algebra generated by $V$ subject to the relation 
$$v_1v_2 + v_2v_1 = 2b(v_1,b_2)1_A$$
where $1_A$ denotes the multiplicative unit in $A$.
\end{exer}
We claim that the above relation is equivalent to the relation $v^2 = b(v,v)1_A$. To see this, we first note that the above condition implies this when we take $v_1 = v_2$. Then for the other direction, consider
$$(v_1 + v_2)^2 = v_1v_2 + v_2v_1 + v_1^2 + v_2^2$$
We then apply our relation, giving us
\begin{align*}
&b(v_1 + v_2, v_1 + v_2) = v_1v_2 + v_2v_1 + b(v_1,v_1) + b(v_2,v_2) \\
\implies & b(v_1 + v_2, v_1 + v_2) - b(v_1, v_1) - b(v_2, v_2) = v_1v_2 + v_2v_1
\end{align*}
Then applying polarization, we arrive at the desired identity.

With this, we want to construct $\Cliff(V,b)$ as the unital algebra satisfying our relation and subject to no others (other than bilinearity of multiplication). Therefore, we can consider the quotient of the tensor algebra $\mathcal{T}(V)$ by the ideal $(v^2 - b(v,v))$ to construct $\Cliff(V,b)$. To characterize it, we think of it as the universal such algebra containing $V$ subject to our relation. Since it is subject to no other relations, we expect this object to be \emph{initial}. It should have a map into every other such algebra satisfying this relation. In other words, for every algebra $A$ with an inclusion $j : V \hookrightarrow A$ such that $j(v_1)j(v_2) + j(v_2)j(v_1) = 2b(v_1,v_2)1_A$, we get a unique map $\Cliff(V,b) \to A$ such that the following diagram commutes
$$\begin{tikzcd}
V \arrow[hookrightarrow]{d} \arrow[hookrightarrow]{dr}{ j} \\
\Cliff(V,b) \arrow[dashed]{r} & A
\end{tikzcd}$$
In other words, the data of a map $\Cliff(V,b) \to A$ is equivalent to a map $j : V \to A$ satisfying the relation we want.

We claim that this characterizes the Clifford algebra up to unique isomorphism. Let $A$ be another algebra with map $j: V\hookrightarrow A$ satisfying the same property we gave above. From the universal property of $\Cliff(V,b)$, we get a unique map $\Cliff(V,b) \to A$. Likewise, the inclusion $V \hookrightarrow \Cliff(V,b)$ gives us a unique map $A \to \Cliff(V,b)$. We claim that these two maps are inverses. We note that both maps are given by $v \mapsto j(v)$ $j(v) \mapsto v$ and extending to products and sums, so we have that they are inverses.

We now want to verify that the construction $\mathcal{T}(V) / (v^2 - b(v,v))$ satisfies this universal property, i.e. the Clifford algebra exists. Given an algebra $A$ with a map $j : V \hookrightarrow A$ satisfying $j(v)^2 - b(v,v) = 0$, define the map $\mathcal{T}(V) \to A$ by $v \mapsto j(v)$ and extending linearly and to products. Then the ideal $(v^2 - b(v,v))$ lies in the kernel of this map, so the map factors through uniquely through $\mathcal{T}(V) / (v^2 - b(v,v))$, so it satisfies the property we laid out.
%
\setcounter{section}{5}
%
\setcounter{thm}{0}
%
\section*{Week 5}
%
\begin{exer}
Continue thinking about what makes an algebra a matrix algebra, either for a regular vector space, or for a super vector space.
\end{exer}
%
\begin{exer}
Is $\mathbb{H}$ isomorphic to an endomorphism algebra $\End(V)$ for some $V$? Does $\mathbb{H}$ admit an irreducible module?
\end{exer}
The quaternions $\mathbb{H}$ are not an endomorphism algebra because they are a division algebra -- there's too many invertible elements! It does admit an irreducible module however, namely itself. To show that it is irreducible, we show that it cannot have any proper invariant subspaces. To show this, we note that for any $q,p \in \mathbb{H}$, we have an element that when multiplied on the left with $q$ gives us $p$, namely $pq\inv$.
%
\begin{exer}
For an algebra $A$, an $A$-module $M$ is indecomposable if it can be expressed as the direct sum
$M = M_1 \oplus M_2$ of submodules $M_1$ and $M_2$. Any algebra acts on itself via left multiplication, which we will call the left regular representation. Is the left regular representation of a Clifford algebra indecomposable?
\end{exer}
%
\begin{quest}
How many irreducible representations are there for any given Clifford algebra $\Cliff(V,b)$. How many indecomposable ones?
\end{quest}
%
\begin{quest}
Does Schur's lemma hold for Clifford modules? Does Maschke's theorem hold?
\end{quest}
%
Clearly, an irreducible module is indecomposable, so this raises the question -- is the left regular representation for a Clifford algebra irreducible?
%
\begin{exer}
Given an $A$-module $M$ and a $B$-modules $N$, how would you realize $M \otimes N$ as a $A \otimes B$ module? What if $A$ and $B$ were superalgebras?
\end{exer}
We have that a module $V$ over an algebra $R$ is equivalent to giving an algebra homomorphism $R \to \End(V)$. Therefore, we have algebra homomorphisms $\varphi : A \to \End(M)$ and $\psi : B \to \End(N)$. Then we can use these maps to define a map $A \times B \to \End(M) \otimes \End(N)$ where $(a,b) \mapsto \varphi(a) \otimes \psi(v)$, which descends to the tensor product. Composing with the canonical isomorphism $\End(M) \otimes \End(N) \to \End(M \otimes N)$ then gives us the $A \otimes B$-module structure we desire on $M \otimes N$.

More explicitly, this more or less does what you expect, where the action of an element $a \otimes b$ is given by
$$(a\otimes b) \cdot (m \otimes n) = am \otimes bn $$
and extending linearly to sums of algebra elements.
In the case of superalgebras, the super tensor product and super vector spaces, this amounts to the same thing as we gave with the isomorphism $\End(V) \otimes \End(W) \to \End(V \otimes W)$, where the first tensor product is now the tensor product of superalgebras, this amounts to the module structure being
$$(a \otimes b) \cdot (m \otimes n) = (-1)^{|b||m|}(am \otimes bn) $$
%
\begin{exer}
Using only the universal property of the Clifford algebra,
\begin{enumerate}
\item Show the map $\iota : V \to \Cliff(V,b)$ is injective
\item Carefully state what it means for the $\Cliff(V,b)$ to be unique, and prove it
\item Can you obtain the $\Z/2\Z$ grading?
\item How do you get maps between Clifford algebras?
\end{enumerate}
\end{exer}
We first state a refined version of the universal property of $\Cliff(V,b)$. For a vector space $V$ with symmetric bilinear form $b : V \times V \to \R$, the \ib{Clifford algebra} is the data of a unital associative algebra $\Cliff(V,b)$ and a map $\iota : V \to \Cliff(V,b)$ such that for any algebra $A$ with a linear map $j : V \to A$ satisfying $j(v)^2 = b(v,v)$, we get a unique algebra homomorphism $\Cliff(V,b) \to A$ such that the following diagram commutes 
$$\begin{tikzcd}
V \arrow[d, "\iota"'] \arrow[dr, "j"]\\
\Cliff(V,b) \arrow[r] & A
\end{tikzcd}$$
\begin{enumerate}
\item Consider the map $j : V \to \mathcal{T}(V) / (v^2 - b(v,v))$ induced by the inclusion map $V \hookrightarrow \mathcal{T}(V)$.  We note that this map is injective, and satisfies the relation we need to get a map $\varphi : \Cliff(V,b) \to \mathcal{T}(V) / (v^2 - b(v,v)$ such that $j = \varphi \circ \iota$. Therefore, $\iota$ must be injective.
\item For uniqueness, suppose $(A, j)$ is another algebra satisfying the universal property of the Clifford algebra. Then we claim that there is a unique isomorphism $\Cliff(V,b) \to A$ such that 
$$\begin{tikzcd}
V \arrow[d, "\iota"'] \arrow[dr, "j"]\\
\Cliff(V,b) \arrow[r] & A
\end{tikzcd}$$
From the universal property of $\Cliff(V,b)$, we get a unique map $\varphi : \Cliff(V,b) \to A$, and since $A$ satisfies the universal property, the map $\iota$ gives us a unique map $\psi : A \to \Cliff(V,b)$. We claim that these maps are inverses (and consequently, isomorphisms). We note that $\psi \circ \varphi : \Cliff(V,b) \to \Cliff(V,b)$ satisfies $(\psi \circ \varphi)(\iota(v)) = \iota(v)$. so it must be the unique map that makes
$$\begin{tikzcd}
V \arrow[d, "\iota"'] \arrow[dr, "\iota"]\\
\Cliff(V,b) \arrow[r] & \Cliff(V,b)
\end{tikzcd}$$
commute. We note that the identity map on $\Cliff(V,b)$ satisfies this property, so by uniqueness, we must have $\psi \circ \varphi = \id$. Repeating the argument with $j$ and $A$, we conclude that $\varphi \circ psi = \id$, so they are inverses.
\item To obtain the grading, we want to show that the assignment $(V,b) \to \Cliff(V,b)$ is functorial. Given vector spaces $V,W$ with symmetric bilinear forms $b_V, b_W$ respectively, and a linear map $T : V \to W$ satisfying $b_W(Tv_1, Tv_2) = b_V(v_1, v_2)$ (i.e. $T^*b_W = b_V$). Then we claim we get an induced algebra homomorphism $T_* : \Cliff(V,b_V) \to \Cliff(W, b_W)$  such that
$$\begin{tikzcd}
(V, b_V) \arrow[r, "T"] \arrow[d, "\iota_V"']& (W, b_W) \arrow[d, "\iota_W"] \\
\Cliff(V, b_V) \arrow[r, "T_*"'] & \Cliff(W, b_W)
\end{tikzcd}$$
commutes. We note that the data of a map $\Cliff(V,b_V) \to \Cliff(W, b_W)$ is equivalent to the data of a linear map $j : V \to \Cliff(W, b_W)$ satisfying $j(v)^2 = b_V(v,v)$. In this case, let $j = \iota_W \circ T$. We note that $(\iota_W \circ T) (v)^2 = b_W(Tv, Tv)$. Then since we have that $T^*b_W = b_V$, we have that this is equal to $b_V(v,v)$, so we do indeed get an induced map $T_*: \Cliff(V,b_V) \to \Cliff(W, b_W)$, which is uniquely defined by the rule
$$T_* (\iota_V(v)) = \iota_W(Tv) $$
We claim that this is functorial, i.e. given $T: (V, b_V) \to (W,b_W)$ and $L : (W, b_W) \to (X, b_X)$, we have that $(L \circ T)_* = L_* \circ T_*$. This follows from looking at the diagram
$$\begin{tikzcd} 
V \arrow[d, "\iota_V"']\arrow[r, "T"] & W \arrow[d, "\iota_W"] \arrow[r, "L"] & X \arrow[d, "\iota_X"]\\
\Cliff(V, b_V) \arrow[r, "T_*"'] & \Cliff(W, b_W) \arrow[r, "L_*"'] & \Cliff(X, b_x)
\end{tikzcd}$$
With that out of the way, we can use the functoriality to obtain the $\Z/2\Z$ grading. Let $(V,b)$ be a vector space $V$ with symmetric bilinear form $b$, and consider the map $-\id_V$, where $v \mapsto -v$. Then we note that 
$$(-\id_V^*b)(v,w) = b(-v,-w) = b(v,w)$$
 so it induces an algebra map $\varphi : \Cliff(V,b) \to \Cliff(V,b)$ which is defined by the property that $\varphi(\iota(v)) = -\iota(v)$. Then let the even subspace of $\Cliff(V,b)$ be the subspace spanned by elements $a$ such that $\varphi(a) = a$, and let the odd subspace of $\Cliff(V,b)$ be the one spanned by elements $a$ such that $\varphi(a) = -a$.
 \item This is answered by the functoriality of $(V,b) \mapsto \Cliff(V,b)$. We get maps between Clifford algebras when we have linear maps that pullback the bilinear forms.
\end{enumerate}
%
\begin{exer}
Give a canonical isomorphism $\End(V) \otimes \End(W) \to \End(V \otimes W)$ in the case of regular vector spaces and super vector spaces.
\end{exer}
Let $A \in \End(V)$ and $B \in \End(W)$. Then define the map 
\begin{align*}
A \otimes B : V \otimes W &\to V \otimes W \\
v \otimes w &\mapsto Av \otimes Bw
\end{align*}
This defines a bilinear mapping $\End(V) \times \End(W) \to \End(V \otimes W)$, so it factors uniquely to map $\varphi : \End(V) \otimes \End(W) \to \End(V \otimes W)$. We claim that this defines an isomorphism. To show this, we note that by dimension, it suffices to show that the map is surjective. To show this, fix bases $\set{v_i}$ and $\set{w_j}$ for $V$ and $W$ respectively. Then $\set{v_i \otimes w_j}$ is a basis for $V \otimes W$. If we can find maps $A,B$ such that $A \otimes B$ maps $v_i \otimes v_j$ to $v_k \otimes v_\ell$ and maps the rest of the basis to $0$, we claim that this implies surjectivity. To see this, we note that any linear map $T \in \End(V \otimes W)$ is defined by its action on $\set{v_i \otimes w_j}$, which it maps to linear combinations of $\set{v_i \otimes w_j}$ therefore, we can construct any linear map we desire out of linear combinations of these elementary linear maps. To construct these elementary linear maps. Then fix $v_i \otimes w_j$ and $v_k \otimes w_\ell$. Then we know there exists a linear map $A \in \End(V)$ that maps $v_i$ to $v_k$ and the rest of the basis to $0$. In addition, we know that there exists a linear map $B \in \End(W)$ that maps $w_j$ to $w_\ell$ and the rest to $0$. Then $A \otimes B$ is the map we desire. Consequently, the map is surjective, and is an isomorphism by dimension count.

In the case that $V$ and $W$ are super vector spaces, write
\begin{align*}
V &= V^0 \oplus V^1 \\
W &= W^0 \oplus W^1
\end{align*}
We then note that the grading for $V$ and $W$ gives natural gradings for $\End(V)$ and $\End(W)$, where the even subspaces are the ones that preserve the grading and the odd subspaces are the ones that reverse the grading. In other words, a map $T \in \End(V)$ is even if $T(V^i) \subset V^i$ and is odd if $T(V^i)  = T(V^{i+1})$, where the addition is done mod $2$. In addition, we have that the gradings of $V$ and $W$ induce a grading on $V \otimes W$ where
\begin{align*}
(V \otimes W)^0 &= (V^0 \otimes W^0) \oplus (V^1 \otimes W^1) \\
(V \otimes W)^1 &= (V^0 \otimes W^1) \oplus (V^1 \otimes W^0)
\end{align*}
Therefore, in the case of $V$ and $W$ being super vector spaces, we want the isomorphism we construct 
$$\End(V) \otimes \End(W) \to \End(V \otimes W)$$
to respect this extra structure, which it does.

However, when we are the super tensor product $\End(V) \otimes \End(W)$ (where we use $\otimes$ to denote the super tensor product rather than the ordinary one), we have to be more careful, since the multiplication is now given by
$$(A \otimes B)(C \otimes D) = (-1)^{|B||C|}(AB \otimes CD) $$
and our original isomorphism no longer works. Define the action of a homoegenous element $A \otimes B$ on $v \otimes w$ by
$$(A \otimes B)(v \otimes w) = (-1)^{|B| |v|}(Av \otimes Bw) $$
we claim that this gives us an algebra map $\End(V) \otimes \End(W) \to \End(V \otimes W)$. To show this, we need to show that 
$$(A \otimes B)(C \otimes D)(v \otimes w) = (-1)^{|B||C|}(AC \otimes BD)(v \otimes W) $$
For the left hand side, unrolling the action we defined givues us
$$(A \otimes B)(C \otimes D)(v \otimes w) = (-1)^{|B||Cv| + |D||v|}(ACv \otimes BDw)$$
We note that $|Cv| = |C| + |v|$ mod $2$, so this gives us
$$ (A \otimes B)(C \otimes D)(v \otimes w) = (-1)^{|B||C| + (|B| + |D|)|v|}(ACv \otimes BDw)$$ 
On the right hand side, we have that 
$$(-1)^{|B||C|}(AC \otimes BD)(v \otimes w) =  (-1)^{|B||C| + |BD||v|}(ACv \otimes BDw)$$
We note that $|BD| = |B| + |D|$ by the definition of a super algebra, so this becomes
$$(-1)^{|B||C|}(AC \otimes BD)(v \otimes w) = (-1)^{|B||C| + (|B| + |D|)|v|}(ACv \otimes BDw)$$
so this is an algebra homomorphism. Then to show this is surjective, we use the same strategy as with the regular tensor product. Fix bases $\set{v_i}$ and $\set{w_j}$ such that they are all homogeneous elements of $V$ and $W$ (i.e. obtained by fixing bases for the even and odd subspaces and concatenating them). Then again, we want to be able to map $v_i \otimes w_j$ to any $v_k \otimes w_\ell$ and the rest to $0$. This has some subtleties regarding the signs of the basis vectors. In the case that $w_j$ and $w_\ell$ are the same parity, this requires $B$ to be even, so the sign will always be positive. Therefore, we can just pick $A$ to be the matrix that maps $v_i \mapsto v_k$ and the rest to $0$, and $B$ to be the matrix that maps $w_j \mapsto w_\ell$, and the rest to $0$. In the case that $w_j$ and $w_\ell$ have opposite parity, the $B$ is odd, and we need to check the cases for the parity of $v_i$. If $v_i$ is even, then again the sign will be positive, and we can do the same thing as the previous case. In the case that $v_i$ is odd, then there will be a negative sign. In this case, we do the same as before, except we replace $A$ with the map that maps $v_i \mapsto -v_k$, giving us the sign we desire. Finally, we want to check that this map respects the grading. Suppose $A \otimes B$ is even, i.e. $A$ and $B$ have the same parity. This then gives surjectivity.
%
\setcounter{section}{6}
%
\setcounter{thm}{0}
%
\section*{Week 6}
%
\begin{exer}
Give The universal property for the tensor product of
\begin{enumerate}
\item Algebras
\item Superalgebras
\end{enumerate}
Can you realize these tensor products as special cases of a more general construction?
\end{exer}
\begin{enumerate}
\item For $R$-algebras $A,B$, the tensor product $A \otimes B$ is another $R$-algebra equipped with a bilinear map $A \times B \to A \otimes B$ such that for any bilinear map $\varphi : A \times B \to C$ to another $R$-algebra $C$ satisfying 
$$\varphi((a,b)(c,d)) = \varphi(ac, bd)$$
we get a unique map $\tilde{\varphi} : A \otimes B \to C$ such that the diagram
$$\begin{tikzcd}
A \times B \ar[d] \ar[r, "\varphi"] & C \\
A \otimes B \ar[ur, "\tilde{\varphi}"']
\end{tikzcd}$$
\item For superalgebras $A,B$, we recall from before that the multiplication in $A \otimes B$ is defined on homogeneous elements as
$$(a_1 \otimes b_1)(a_2 \otimes b_2) = (-1)^{|b_1||a_2|} (a_1a_2 \otimes b_1b_2)$$
where $|b_1|$ denotes the parity of the $b_1$. Therefore, the universal property for super algebras needs the small modification that the map $\varphi A \times B \to C$ needs to satisfy
$$\varphi((a,b)(c,d)) = (-1)^{|b||c|}\varphi(ac,bd) $$
in order to factor through the tensor product $A \otimes B$.
\end{enumerate}
%
\begin{exer}
Using the notation that $C_{p,q}$ is the Clifford algebra of $\R^{p|q}$, we know that if $C_{p,q}$ is a matrix algebra, then $C_{p+1,q+1}$ is a matrix algebra. Is the converse true?
\end{exer}
%
\begin{exer}
For a Clifford algebra $C_{p,q}$, can you identify the even subalgebra $C_{p,q}^0$ as a different Clifford algebra? If so, is the isomorphism with or without grading?
\end{exer}
We note that for $C_{p,q}$, the even and odd subspaces are the same dimension, so the even subalgebra is an algebra of half the dimension of $C_{p,q}$, which has dimension $2^{p + q}$. This leads us to expect that it should be isomorphic to the Clifford algebra $C_{p-1,q}$ or $C_{p,q-1}$. By definition, it will be generated by all pairwise products of the $e_i$. From a simple computation, we get that
$$(e_ie_j)^2 = e_ie_je_ie_j = -e_i^2e_j^2 $$
giving us that 
$$(e_ie_j)^2 = \begin{cases} 
1 & e_i^2 \neq e_j^2 \\
-1 & e_i^2 = e_j^2
\end{cases}$$
For a basis vector $e_i$, denote it as $e_i^+$ or $e_i^-$ depending on whether it squares to plus or minus one, writing $C_{p,q}$ as generated by the basis vectors $e_1^+ \ldots e_p^+$ and $e_1^- \ldots e_q^-$. We have that a generating set for the even subspace (assuming $q \neq 0$) is the set 
$$\set{e_1^-e_j^+ ~:~ 1 \leq j \leq p} \cup \set{e_1^-e_k^- ~:~ 2 \leq k \leq q}$$
Noting that the elements in the first set square to $1$ and the elements in the second set square to $-1$, we get that the even subspace will be isomorphic to $C_{p,q-1}$ via the mappings
$$e_1^-e_j^+ \mapsto e_j^+ \qquad e_1^-e_k^- \mapsto e_{k-1}$$
We note in the special case that $p=1$, this gives us $C_{0,q}^0 \cong C_{0,q-1}$. Another equally good generating set would be
$$\set{e_1^+e_j^- ~:~ 1 \leq j \leq q} \cup \set{e_1^+e_k^+ ~:~ 2 \leq k \leq p} $$
where we now have that elements of the first set square to $-1$ and the elements of the second set square to $1$. Via a similar mapping, we get that $C_{p,q}^0 \cong C_{q,p-1}$. As a corollary, this gives us that $C_{p,q} \cong C_{q+1,p-1}$. 
%
\begin{exer}
For an algebra $A$, an ideal $I \subset A$ is a subalgebra such that for any $b \in I$, $ab \in I$ for all $a \in A$. An algebra $A$ is said to be \ib{simple} if it admits no nontrivial ideals i.e. the only ideals are $0$ and $A$. What are ideals in the Clifford algebra? Which Clifford Algebras are simple?
\end{exer}
We first have a nice lemma
%
\begin{lem*}
Let $A$ be a division algebra. Then the algebra $M_nA$ of matrices with entries in $A$ is a simple algebra.
\end{lem*}
%
\begin{proof}
Let $I \subset M_nA$ be an ideal that is not the $0$ ideal. Then let $M \subset I$ be a nontrivial matrix., which must have some entry $M^i_j \neq 0$. Then let $T$ be the matrix where
$$T^k_\ell = \begin{cases} 
(M^i_j)\inv & k = j, \ell= i \\
0 & \text{otherwise}
\end{cases} $$
Then $MT$ will be the matrix with $1$ in the $(i,i)$ entry and $0$ elsewhere. We can then use elementary matrices to multiply with $MT$ to be a $1$ in any of the diagonal entries, which implies that the identity matrices is in our ideal. Therefore, any nontrivial ideal must be all of $M_nA$, so $M_nA$ is simple.
\end{proof}
%
\begin{exer}
If we have an ideal $I$ of a superalgebra $A$, what conditions do we need to put on $I$ such that the quotient $A/I$ is also a super algebra?
\end{exer}
We note that the grading of a vector space $V = V^0 \oplus V^1$ is equivalent to the existence of an operator $\varepsilon : V \to V$ such that $\varepsilon\vert_{V^0} = \id_{V^0}$ and $\varepsilon\vert_{V^1} = -\id_{V^1}$. Given any such operator, we recover the decomposition as the $\pm 1$ eigenspaces. In the case of a superalgebra, we want the grading operator to respect the other algebra structure, i.e. if we have $A$ graded as $A = A^0 \oplus A^1$, we want
$$A^iA^j = A^{i + j \text{ mod } 2} $$
This translates to $\varepsilon$ being a map of algebras, rather than just a linear map, i.e. $\varepsilon(ab) = \varepsilon(a)\varepsilon(b)$. Therefore, if we want $A/I$ to have a grading compatible with the multiplication, we want $\varepsilon$ to descend to a map $\tilde{varepsilon} : A/I \to A/I$, i.e.
$$\begin{tikzcd} 
A \ar[d] \ar[r, "\varepsilon"] & A \ar[d] \\
A /I \ar[r, "\tilde{\varepsilon}"'] & A/I
\end{tikzcd}$$
commutes. From the universal property of the quotient, this amounts to requiring that $\varepsilon(I) \subset I$, and since $\varepsilon$ is an isomorphism, this is equivalent to $\varepsilon(I) = I$.
%
\begin{exer}
The center for an algebra $A$ consists of all the elements $a \in A$ that commute with all the other elements. Is there a different notion for superalgebras? If so, what?
\end{exer}
%
\begin{exer}
For an algebra $A$, the \ib{opposite algebra} $A^\text{op}$ an algebra define by the same underlying vector space, but the multiplication $a*b$ in $A^\text{op}$ is instead $ba$ (where this product is in $A$). Does this construction work for superalgebras? What is $C_{p,q}^\text{op}$?
\end{exer}
The idea needs a slight modification for the case of superalgebras. Since we're commuting two elements past each other in the multiplication, we want $a*b = (-1)^{|a||b|}ba$. Defining it this way, we investigate $C_{p,q}^\text{op}$, where again, we use $*$ to denote the multiplication in the opposite algebra.

We note that a basis $e_1^+ \ldots e_p^+, e_1^- , \ldots e_q^-$ for $\R^{p|q}$ is still a generating set for the the opposite algebra, so all that needs to be done is to investigate how the relations change. Our first observation is that $e_i^\pm * e^i_\pm = -(e_i^\pm)^2$, so now all of the positive basis elements square to negative one, and all the negative basis elements square to positive ones. This motivates us to suspect that the opposite algebra is in fact $C_{q,p}$ under the obvious map $e_i^\pm \mapsto e_i^\mp$
%
\begin{exer}
Recall from earlier that we constructed a subgroup of the multiplicative group of $C_{p,q}$ generated by the unit vectors in $\R^{p|q}$. Call this group $\Pin(p,q)$, and define $\Spin(p,q) = \Pin(p,q) \cap C_{p,q}^0$. For small values of $p,q$, identify these groups. (Hint : They will be Lie groups).
\end{exer}
%
\setcounter{thm}{0}
%
\setcounter{section}{7}
%
\section*{Week 7}
%
\begin{exer}
One way to construct the tensor product $A \otimes B$ of algebras is as a quotient of a free algebra modulo ideals giving us relations that we want. However, we already have the tensor product of vector spaces, so all that remains is to give an algebra structure on the underlying vector space $A \otimes B$. How do you do this?
\end{exer}
We have that an algebra $A$ is the data of a vector space $A$, along with a distinguished element $1_A$, and a linear map $\varphi : A \to \End(A)$ such that $\varphi(1_A) = \id_A$. This gives us the algebra multiplication $ab = \varphi(a)(b)$. We can then use this to construct an algebra structure on the vector space $A \otimes B$. Let $j : A \times B \to A \otimes B$ be the bilinear map $A \times B \to A \otimes B$ where $(a,b) \mapsto a \otimes b$, and let $1_A,1_B$ and $\varphi_A,\varphi_B$ be the units and maps to the endomorphism algebras for $A$ and $B$ respectively. Then let $1_{A \otimes B}$ by $j(1_A, 1_B) = 1_A \otimes 1_B$, and let $\varphi_{A \otimes B}$ be the map $a \otimes b \mapsto \varphi_A \otimes \varphi_B \in \End(A) \otimes \End(B)$, which is canonically isomorphic to $\End(A \otimes B)$. We note that $1_A \otimes 1_B \mapsto \id_A \otimes \id_B = \id_{A \otimes B}$, so this map defines the algebra structure on $A \otimes B$.
%
\begin{exer}
We constructed Clifford algebras where the base vector spaces are $\R$-vector spaces. The same construction (with minor modifications) can be made over $\C$. Can you also do this for $\mathbb{H}$? Do similar isomorphism theorems hold? Is there a relation between the real Clifford algebras and the complex ones?
\end{exer}
\begin{rem*}
Another fun thing to think about, can you construct Clifford algebras over $R$-modules for arbitrary rings $R$?
\end{rem*}
%
\begin{exer}
We've proven that $C_{p,q}^{\text{op}} \cong C_{q,p}$. Then note that $C_{p,q} \otimes C_{q,q} \cong C_{p + q, p + q}$, which is a matrix algebra, which will be isomorphic to $\End((\R^{1|1})^{\otimes n})$. However, this isomorphism is not very natural, since it will implicitly need a choice of basis. Is there a more natural vector space that $C_{p,q} \otimes C^\text{op}_{p,q}$ acts on?
\end{exer}
We have that the dimension of $C_{p+q, p+q}$ is $2^{2(p+q)}$, so we need the vector space to be $2^{p+q}$ dimensional. In addition, since we know that the even and odd subspaces need to have the same dimension. Conveniently, $C_{p,q}$ satisfies both of these properties. In addition, both $C_{p,q}$ and $C_{p,q}^\text{op}$ have natural actions on $C_{p,q}$ (namely multiplication), so all the evidence points us to try to find a map $\varphi: C_{p,q} \otimes C_{p,q}^\text{op} \to \End(C_{P,q})$ (where $\End$ denotes the space of linear maps, not the space of algebra endomorphisms. Define $\varphi$ on homogeneous elements of $C_{p,q} \otimes C_{p,q}^\text{op}$ by its action on homogeneous elements of $C_{p,q}$ (i.e even and odd elements) 
$$\varphi(a \otimes b)(v) = (-1)^{|b||v|} a(b*v)$$
where $*$ denotes the multiplication in $C_{p,q}^\text{op}$ and extending linearly to sums. The sign is motivated by the fact that the opposite multiplication in commutes $b$ and $v$. We then verify that this is an algebra map. We have that 
\begin{align*}
\varphi((a_1\otimes b_1)(a_2 \otimes b_2))(v) &= (-1)^{|b_1||a_2|}\varphi(a_1a_2 \otimes b_1*b_2)(v) \\
&= (-1)^{|b_1||a_2| + |b_1||b_2|}\varphi(a_1a_2 \otimes b_2b_1)(v) \\
&= (-1)^{|b_1||a_2| +|b_1||b_2| + |b_2b_1||v|}a_1a_2vb_2b_1 \\
&= (-1)^{|b_1||a_2| + |b_1||b_2| + |b_2||v| + |b_1||v|} a_1a_2vb_2b_1
\end{align*}
We then compute
\begin{align*}
(\varphi(a_1 \otimes b_1) \circ \varphi(a_2 \otimes b_2)(v) &= (-1)^{|b_2||v|} \varphi(a_1 \otimes b_1)(a_2vb_2) \\
&= (-1)^{|b_1||a_2| + |b_1||b_2| + |b_2||v| + |b_1||v|} a_1a_2vb_2b_1
\end{align*}
So they are equal, so $\varphi$ is an algebra map. We then need to check that it is a superalgebra map, i.e. it preserves grading. We observe for $a \otimes b$, 
$$|\varphi(a\otimes b)(v)| = |avb| = |a| + |v| + |b| $$
Therefore, if $a$ and $b$ are the same parity (i.e. $a \otimes b$ is even), then this is the parity of $v$, so $\varphi(a \otimes b)$ is also even. If $a$ and $b$ are different parities, then the parity of $|avb|$ will be the opposite, so $\varphi(a \otimes b)$ will be odd, just like $a \otimes b$. This gives us that $\varphi$ preserves the gradings, so it is a superalgebra map. Then since $C_{p,q} \otimes C_{p.q}^\text{op}$ is a matrix algebra, it is simple. Then since the kernel of the $\varphi$ is an idea and $\varphi$ is clearly not $0$, it must have trivial kernel, and since the domain and codomain it the same dimension, we have that $\varphi$ must be an isomorphism. Therefore, we have a canonical isomorphism
$$\varphi : C_{p,q} \otimes C_{p,q}^\text{op} \to \End(C_{p,q}) $$
%
\begin{exer}
Continue thinking about properties of $\Spin(p,q)$ and $\Pin(p,q)$. Continuing on last week, identify what low dimensional Lie groups they're be isomorphic to. Are they compact? Connected? What is $\pi_0(\Pin(p,q))$?
\end{exer}
We first begin by identifying the orthgonal $O(p,q)$ for $\R^{p|q}$ and its Lie algebra. Let $B$ denote the bilinear form for $\R^{p,q}$, and let $M$ denote its matrix in the standard basis, i.e. the diagonal matrix with $p$ ones the the diagonal and $q$ negative ones. Then we have that $B(v,w) = v^TMw$, where $v$ and $w$ are written in the standard coordinates. Then we have that 
$$O(p,q) = \set{A \in GL(p+q,\R) ~|~ v^TMw = v^TA^TMAw ~ \text{for all } v,w \in \R^{p,q}} $$
We note that in particular, this is equivalent to 
$$O(p,q) = \set{A \in GL(p+q, \R) ~:~ A^TMA = M} $$
Since $M$ will have determinant $\pm 1$, this implies that $(\det A)^2 = \pm 1$ for all $A \in O(p,q)$, so it will again have $2$ components. To compute the Lie algebra $\mathfrak{o}(p,q)$, we let $\varphi : GL(p+q, \R) \to M_{p + q}$ by $\varphi(X) = X^TMX$, which will be a constant rank map (since it is equivariant with respect to appropriate group actions by multiplication), so the kernel $\ker d\varphi_I$ will be the Lie algebra $\mathfrak{o}(p,q)$. To compute the differential, we prove $\varphi$ with curves based at $I$, and compute for $X \in M_{p+q}\R$
\begin{align*}
\varphi(tX + I) &= (tX + I)^T M (tX + I) \\
&= t^2X^TMX + t(MX + X^TM) + M
\end{align*}
which has linear term $MX + X^TM$, so $d\varphi_I(X) = MA + A^TM$. Therefore, we get that 
$$\mathfrak{o}(p,q) = \set{X \in M_{p+q}\R ~:~ MX = -X^TM} $$
an easy application on this identity shows that $\mathfrak{o}(p,q)$ is closed under the commutator bracket, so we get that $\mathfrak{o}(p,q)$ is a Lie algebra, as expected. In order to find out more about $\Pin(p,q)$ and $\Spin(p,q)$, we want to embed $\mathfrak{o}(p,q) = \mathfrak{so}(p,q)$ into $C_{p,q}$ with the commutator bracket (since we suspect that this is the Lie algebra for the group of units $C_{p,q}^\times$), and see what happens with the exponential map. 

To do this, we're going to assume some things we haven't fully proven yet, namely that $\Pin(p,q)$ and $\Spin(p,q)$ are smooth submanifolds of $C_{p,q}$, so we can compute the compute the differential of the map
\begin{align*}
\varphi : \Pin(p,q) &\to O(p,q) \\
\varphi(a)(v) &= ava^T
\end{align*}
where $a^T$ is the map that reverses the order of products, extended linearly to the entire algebra. We want to compute $d\varphi_1$. To do this, we have that 
\begin{align*}
\varphi(ta + 1)(v) &= (ta + 1)v(ta^T + 1) \\
&= t^2ava + tav + tva^T + v
\end{align*}
which has linear term $av + va^T$. So $d\varphi_1(A) = X$ where $\varphi_X = Xv+  vX^T$. We know that since this maps onto $\mathfrak{o}(p,q)$ that in particular this requires $Xv + vX^T \in \R^{p|q}$ for all $v \in \R^{P|q}$. We also note that that dimension of $\mathfrak{o}(p,q)$ is $n(n-1)/2 = \binom{n}{2}$, so we're looking for a certain number of linearly independent algebra elements satisfying this relation. We note that the set $\set{e_ie_j}$ of pairwise products works (and is the right number), since 
$$e_ie_jv + ve_je_i = 4B(e_j,v)e_i \in V$$
So we expect this to span the Lie algebra of $\Pin(p,q)$. From another piece of guess work, we want to formally exponentiate these elements, i.e. 
$$e^a = \sum_{i = 0}^\infty \frac{a^n}{n!} $$
If we look at the elements $e_ie_j$, there are a few cases to consider. In the case that $e_i^2 = e_j^2$, we have that $(e_ie_j)^2 = e_ie_je_ie_j = -e_i^2e_j^2 = -1$. In that case, we first note that 
\begin{align*}
(e_ie_j)^2  &= -1 \\
(e_ie_j)^3 &= -e_ie_j \\
(e_ie_j)^4 &= -(e_ie_j)^2 = 1 \\
(e_ie_j)^6 &= e_ie_j
\end{align*}
Then rearranging the terms in the sum, we get 
$$e^{te_ie_j} = \left(\sum_{k = 1}^\infty \frac{(-1)^{k+1}t}{2k !} \right) + \left(\sum_{k = 1}^\infty \frac{(-1)^{k+1}te_ie_j}{(2k-1)!} \right) = \cos t + (\sin t) e_ie_j$$
In the case that $e_i^2 \neq e_j^2$, we have that $(e_ie_j)^2 = 1$, which gives us
\begin{align*}
(e_ie_j)^2 &= 1 \\
(e_ie_j)^3 &= e_ie_j
\end{align*}
So the series becomes
$$e^{te_ie_j} = \left( \sum_{k=1}^\infty \frac{t}{2k !} \right)  + \left( \sum_{k = 1}^\infty \frac{te_ie_j}{(2k - 1)!}\right) = \cosh t + (\sinh t)e_ie_j$$
which are some very nice formulas indeed!
%
\begin{exer}
Continue thinking about past problems. Construct the table of Clifford algebras, continue progress on identifying matrix algebras, determining which Clifford algebras are simple, etc.
\end{exer}
%
\section*{Week 8}
%
\begin{exer}
Last week, we constructed an isomorphism $C_{p,q} \otimes C_{p,q}^\text{op} \to \End(C_{p,q})$. In general, there always exists a map $A \otimes A^\text{op} \to \End(A)$ given by the same map. However, this does not always define an isomorphism. What is the obstruction to this being an isomorphism? Try out on the case that $A = \R \times \R$.
\end{exer}
%
\begin{exer}
The Lie algebra is supposed to be something along the lines ``The even subalgebra of the $2$-filtered subalgebra minus the scalars." Make sense of this
\end{exer}
%
\begin{exer}
From before, we posed the question as to whether $C_{p+1,q+1}$ being a matrix algebra implied that $C_{p,q}$ was one. A more general question is that if we had that $A \otimes \End(V) \cong \End(W)$, can we conclude that $A$ is a matrix algebra? 
\end{exer}
%
We first prove some things about modules over some endmorphism algebra $\End(V)$. We have that the standard action of $\End(V)$ on $V$ gives $V$ the structure of an $\End(V)$-module, and that this module is irreducible (which we use interchangeably with simple), since the orbit of any vector $v \in V$ is all of $V$. We claim that this is the only irreducible $\End(V)$ module up to isomorphism. To see this, consider $\End(V)$ as a module over itself, with the algebra action given by left multiplication. Then if we fix a basis for $V$, we get isomorphisms $V \cong \R^n$ and $\End(V) \cong M_n\R$. Then we have a chain of left ideals $0 = I_0 \subset I_1 \subset I_2 \subset \ldots \subset  I_n$, where $I_k$ is the set of matrices with the first $k$ columns possibly nonzero, and the rest all zero. In particular, we have that the module $I_k / I_{k-1}$ is isomorphic to the module $V$, which is irreducible.

Then let $W$ be an arbitrary irreducible $\End(V)$-module. If we fix $w \in W$, then we get a module map $\varphi : \End(V) \to W$ where $\varphi(M) = M \cdot w$, where the right hand side is the algebra action on $W$. In particular, we have that the image of $\varphi$ will be a submodule of $W$, which is necessarily $0$ or all of $W$ since $W$ is irreducible. Since $\varphi$ is not the zero map, we conclude that $\varphi$ is surjective, so $W$ is a quotient of $\End(V)$ as an $\End(V)$ module. Then we know that there must exist some smallest $0 < k < n$ such that the ideal $\varphi(I_k) \neq 0$. Then since $I_{k-1}$ is mapped to $0$, $\varphi$ factors through the quotient to give a nonzero map $I_k / I_{k-1} \to W$. Then since $I_k / I_{k-1}$ is irreducible, and the map is nonzero, this map must be an isomorphism. Therefore $W$ is isomorphic to the standard representation $V$.

Another fact that we want to prove is that given any (associative and unital) $\R$-algebra $A$ and $U$ a simple $A$-module, we get that $U \otimes V$ is a simple $A \otimes \End(V)$ module. 
%
\begin{lem*}
Given an algebra $A$ and an irreducible $A$-module $U$, for any $u,u' \in U$, there exists $\alpha \in A$ such that $\alpha \cdot u = u'$.
\end{lem*}
%
\begin{proof}
We have that $A \cdot u$ is a submodule of $U$ that is nonzero, so it must be all of $U$. Therefore, we must have some $\alpha \in A$ such that $\alpha \cdot u = u'$.
\end{proof}
By fixing a basis for $V$, we get isomorphisms $U \otimes V \cong U \otimes \R^n$ and $A \otimes \End(V) \cong A \otimes M_n\R$. Then given an arbitrary elements $u^i \otimes e_i$ and $(u^i)' \otimes e_i$ (where the $e_i$ are the standard basis vectors for $\R^n$), Then let $\alpha_i \in A$ where $\alpha^i \cdot u^i = (u^i)'$ and let $E_{ii}$ denote the matrix with only a $1$ in the $(i,i)$ entry and zeroes elsewhere. Then $\alpha^i \otimes E_{ii} \cdot u^i \otimes e_i = (u^i)' \otimes e_i$, so $U \otimes V$ is simple, since the algebra action is transitive.
%
\begin{exer}
The next few problems requires some knowledge of complex Clifford algebras. Construct and explore them.
\end{exer}
%
We note that there can't be a distinction $C_{p,q}$ when the ground field is $\C$, since if something squares to $-1$, we can multiply it by $i$ to make it square to $1$. Therefore, we only need to consider the Clifford algebra $C_n$, which is generated by $\C^n$ with the standard Hermitian bilinear form. We note that the first few explicit isomorphisms we constructed earlier all satisfy the Clifford relation, and will certainly satisfy that relation if we extend the field of scalars to $\C$, so this gives us that $C_n \cong C_{n,0} \otimes C \cong C_{0,n} \otimes \C$.
%
\begin{exer}
Isomorphism classes of left $A$-modules, denoted $[ _A \mathsf{Mod} ]$ form a commutative monoid under direct sum. In the case of $C_{p,q}$, what monoid is this isomorphic to? First try this with complex Clifford algebras
\end{exer}
%
\begin{exer}
Given an algebra map $\varphi: A \to B$, this induces a map $[ _B \mathsf{Mod}]$, where given any $B$-module $M$, we can derive an $A$-module structure by $a \cdot m = \varphi(a) \cdot m$. In particular, we have an inclusion $C_{p,q} \hookrightarrow C_{p,q+1}$, which will give us a pullback map $[ _{C_{p,q+1}}\mathsf{Mod} ] \to [ _{C_{p,q}}\mathsf{Mod}]$. We can compute the cokernel of this map, which tells us the degree to which $C_{p,q}$ modules fail to extend $C_{p,q+1}$-modules. Again, first try this for complex Clifford Algebras.
\end{exer}
%
\end{document}